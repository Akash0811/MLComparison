# Importing the dataset
dataset = read.csv('Data.csv')
View(dataset)
dataset = dataset[2:5]
# Importing the dataset
dataset = read.csv('Data.csv')
dataset = dataset[2:]
dataset = dataset[2:-1]
# Importing the dataset
dataset = read.csv('Data.csv')
dataset = dataset[2:-1]
dataset = dataset[2:11]
View(dataset)
dataset$Class = factor(dataset$Class , levels=c(0,1))
View(dataset)
# Importing the dataset
dataset = read.csv('Data.csv')
dataset = dataset[2:11]
dataset$Class = factor(dataset$Class , levels=c(2,4))
View(dataset)
library(caTools)
set.seed(123)
split = sample.split(dataset$Class, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
library(dataPreparation)
scales <- build_scales(training_set, cols = "auto",
verbose = TRUE)
training_set[,1:9] = fast_scale(training_set[,1:9], scales = scales,
verbose = TRUE)
test_set[,1:9] = fast_scale(test_set[,1:9], scales = scales, verbose = TRUE)
View(training_set)
# Fitting Logistic REgression to the Training Set
classifier = glm(formula = Class ~ .,
family = binomial,
data = training_set)
summary(classifier)
# Predicting the test set results
prob_pred = predict(classifier, type = 'response' , newdata = test_set)
y_pred = ifelse(prob_pred > 0.5, 1,0)
cm = table(test_set[,3],y_pred)
cm
cm = table(test_set[,10],y_pred)
cm
(cm[0,0]+cm[1,1])/171
cm[0,0]
(108+57)/171
# KNN Classifier
# Importing the dataset
dataset = read.csv('Data.csv')
dataset = dataset[2:11]
dataset$Class = factor(dataset$Class , levels=c(2,4))
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Class, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
library(dataPreparation)
scales <- build_scales(training_set, cols = "auto",
verbose = TRUE)
training_set[,1:9] = fast_scale(training_set[,1:9], scales = scales,
verbose = TRUE)
test_set[,1:9] = fast_scale(test_set[,1:9], scales = scales, verbose = TRUE)
# Fitting Logistic REgression to the Training Set
# classifier = glm(formula = Purchased ~ .,
#                  family = binomial,
#                data = training_set)
#
# summary(classifier)
# Create classifier here
# Fitting and Predicting
library(class)
y_pred = knn(train = training_set[,1:2],
test = test_set[,1:2],
cl = training_set$Purchased,
k = 5)
# # Predicting the test set results
# prob_pred = predict(classifier, type = 'response' , newdata = test_set)
# y_pred = ifelse(prob_pred > 0.5, 1,0)
cm = table(test_set[,3],y_pred)
cm
cm
cm = table(test_set[,10],y_pred)
cm
y_pred = knn(train = training_set[,1:9],
test = test_set[,1:9],
cl = training_set$class,
k = 5)
training_set[,1:9]
training_set$class
y_pred = knn(train = training_set[,1:9],
test = test_set[,1:9],
cl = training_set$Class,
k = 5)
cm = table(test_set[,10],y_pred)
cm
(108+56)/171
# Fitting Logistic REgression to the Training Set
# classifier = glm(formula = Purchased ~ .,
#                  family = binomial,
#                data = training_set)
#
# summary(classifier)
# Create classifier here
library(e1071)
# SVM Classifier
# Importing the dataset
dataset = read.csv('Data.csv')
dataset = dataset[2:11]
dataset$Class = factor(dataset$Class , levels=c(2,4))
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Class, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
library(dataPreparation)
scales <- build_scales(training_set, cols = "auto",
verbose = TRUE)
training_set[,1:9] = fast_scale(training_set[,1:9], scales = scales,
verbose = TRUE)
test_set[,1:9] = fast_scale(test_set[,1:9], scales = scales, verbose = TRUE)
classifier = svm(formula = Class ~.,
data = training_set,
type = 'C-classification',
kernel = 'linear')
# Predicting the test set results
y_pred = predict(classifier, newdata = test_set)
cm = table(test_set[,10],y_pred)
cm
# SVM Kernel Classifier
# Importing the dataset
dataset = read.csv('Data.csv')
dataset = dataset[2:11]
dataset$Class = factor(dataset$Class , levels=c(2,4))
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Class, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
library(dataPreparation)
scales <- build_scales(training_set, cols = "auto",
verbose = TRUE)
training_set[,1:9] = fast_scale(training_set[,1:9], scales = scales,
verbose = TRUE)
test_set[,1:9] = fast_scale(test_set[,1:9], scales = scales, verbose = TRUE)
# Fitting Logistic REgression to the Training Set
# classifier = glm(formula = Purchased ~ .,
#                  family = binomial,
#                data = training_set)
#
# summary(classifier)
# Create classifier here
library(e1071)
classifier = svm(formula = Class ~.,
data = training_set,
type = 'C-classification',
kernel = 'radial')
# Predicting the test set results
y_pred = predict(classifier, newdata = test_set)
cm = table(test_set[,10],y_pred)
cm
# Naive Bayes Classifier
# Importing the dataset
dataset = read.csv('Data.csv')
dataset = dataset[2:11]
dataset$Class = factor(dataset$Class , levels=c(2,4))
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Class, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
library(dataPreparation)
scales <- build_scales(training_set, cols = "auto",
verbose = TRUE)
training_set[,1:9] = fast_scale(training_set[,1:9], scales = scales,
verbose = TRUE)
test_set[,1:9] = fast_scale(test_set[,1:9], scales = scales, verbose = TRUE)
# Fitting Logistic REgression to the Training Set
# classifier = glm(formula = Purchased ~ .,
#                  family = binomial,
#                data = training_set)
#
# summary(classifier)
# Create classifier here
library(e1071)
classifier = naiveBayes(training_set[,-10],
training_set$Class)
# Predicting the test set results
y_pred = predict(classifier, newdata = test_set)
cm = table(test_set[,10],y_pred)
cm
(106+52)/171
# Decision Tree Classifier
# Importing the dataset
dataset = read.csv('Data.csv')
dataset = dataset[2:11]
dataset$Class = factor(dataset$Class , levels=c(2,4))
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Class, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
library(dataPreparation)
scales <- build_scales(training_set, cols = "auto",
verbose = TRUE)
training_set[,1:9] = fast_scale(training_set[,1:9], scales = scales,
verbose = TRUE)
test_set[,1:9] = fast_scale(test_set[,1:9], scales = scales, verbose = TRUE)
# Fitting Logistic REgression to the Training Set
# classifier = glm(formula = Purchased ~ .,
#                  family = binomial,
#                data = training_set)
#
# summary(classifier)
# Create classifier here
library(rpart)
classifier = rpart(Class ~.,
data = training_set)
# Predicting the test set results
y_pred = predict(classifier, newdata = test_set[-10], type = "class")
cm = table(test_set[,3],y_pred)
cm
cm = table(test_set[,10],y_pred)
cm
(108+55)/171
# Importing the dataset
dataset = read.csv('Data.csv')
dataset = dataset[2:11]
dataset$Class = factor(dataset$Class , levels=c(2,4))
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Class, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
library(dataPreparation)
scales <- build_scales(training_set, cols = "auto",
verbose = TRUE)
training_set[,1:9] = fast_scale(training_set[,1:9], scales = scales,
verbose = TRUE)
test_set[,1:9] = fast_scale(test_set[,1:9], scales = scales, verbose = TRUE)
# Fitting Logistic REgression to the Training Set
classifier = glm(formula = Class ~ .,
family = binomial,
data = training_set)
summary(classifier)
# Predicting the test set results
prob_pred = predict(classifier, type = 'response' , newdata = test_set)
y_pred = ifelse(prob_pred > 0.5, 1,0)
cm = table(test_set[,10],y_pred)
cm
